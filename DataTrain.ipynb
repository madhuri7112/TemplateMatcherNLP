{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Article:\n",
    "    def __init__(self, id, title, content, link):\n",
    "        self.id = id\n",
    "        self.title = title\n",
    "        self.content = content\n",
    "        self.link = link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetchArticles():\n",
    "    files = [\"xaa\",\"xab\", \"xac\", \"xad\", \"xae\"]\n",
    "    articles = {}\n",
    "    for filename in files:\n",
    "        with open(filename) as data_file:\n",
    "            fileData = data_file.readlines()\n",
    "        for articleData in fileData:\n",
    "            articleComponents = articleData.split(\"\\t\")\n",
    "            articles[articleComponents[0]] = (Article(articleComponents[0], articleComponents[1], articleComponents[2], articleComponents[3]))\n",
    "            \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles = fetchArticles()\n",
    "titles = [article.title for article in articles.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6701"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smCount = 0\n",
    "winCount = 0\n",
    "dieCount = 0\n",
    "injureCount = 0\n",
    "celebrateCount = 0\n",
    "fineCount = 0\n",
    "banCount = 0\n",
    "namedCount = 0\n",
    "tweetCount = 0\n",
    "trollCount = 0 \n",
    "shareCount = 0\n",
    "questionCount = 0\n",
    "inviteCount = 0 \n",
    "payCount = 0\n",
    "recordCount = 0\n",
    "\n",
    "smFile = open('sm', 'w')\n",
    "winFile = open('win', 'w')\n",
    "dieFile = open('die', 'w')\n",
    "injureFile = open('injure', 'w')\n",
    "celebrateFile = open('celebrate', 'w')\n",
    "fineFile = open('fine', 'w')\n",
    "banFile = open('ban', 'w')\n",
    "namedFile = open('named', 'w')\n",
    "tweetFile = open('tweet', 'w')\n",
    "trollFile = open('troll', 'w')\n",
    "shareFile = open('share', 'w')\n",
    "questionFile = open('question', 'w')\n",
    "inviteFile = open('invite', 'w')\n",
    "payFile = open('pay', 'w')\n",
    "recordFile = open('record', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testForSm(sentence):\n",
    "    if ':' in sentence:\n",
    "        return True\n",
    "    if any([wordnet_lemmatizer.lemmatize(word) == 'say' for word in words]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def testForDie(sentence):\n",
    "    if any([wordnet_lemmatizer.lemmatize(word) in ['die', 'kill', 'dy'] for word in words]):\n",
    "        return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer() \n",
    "for title in titles:\n",
    "    words = nltk.word_tokenize(title)\n",
    "    if testForSm(title):\n",
    "        smCount += 1\n",
    "        smFile.write(title)\n",
    "        smFile.write('\\n')\n",
    "    if testForDie(title):\n",
    "        dieCount += 1\n",
    "        dieFile.write(title)\n",
    "        dieFile.write('\\n')\n",
    "    if any([wordnet_lemmatizer.lemmatize(word) == 'win' for word in words]):\n",
    "        winCount+=1\n",
    "        winFile.write(title)\n",
    "        winFile.write('\\n')\n",
    "    if any([wordnet_lemmatizer.lemmatize(word) in ['injure','injury', 'injured'] for word in words]):\n",
    "        injureCount+=1\n",
    "        injureFile.write(title)\n",
    "        injureFile.write('\\n')\n",
    "    if any([wordnet_lemmatizer.lemmatize(word) == 'celebrate' for word in words]):\n",
    "        celebrateCount+=1\n",
    "        celebrateFile.write(title)\n",
    "        celebrateFile.write('\\n')\n",
    "    if any([wordnet_lemmatizer.lemmatize(word) in ['fined','fine'] for word in words]):\n",
    "        fineCount+=1\n",
    "        fineFile.write(title)\n",
    "        fineFile.write('\\n')\n",
    "    if any([wordnet_lemmatizer.lemmatize(word) in ['banned','ban'] for word in words]):\n",
    "        banCount+=1  \n",
    "        banFile.write(title)\n",
    "        banFile.write('\\n')\n",
    "    if any([wordnet_lemmatizer.lemmatize(word) in ['named'] for word in words]):\n",
    "        namedCount+=1\n",
    "        namedFile.write(title)\n",
    "        namedFile.write('\\n')\n",
    "    if any([wordnet_lemmatizer.lemmatize(word) in ['tweet'] for word in words]):\n",
    "        tweetCount+=1\n",
    "        tweetFile.write(title)\n",
    "        tweetFile.write('\\n')\n",
    "    if any([wordnet_lemmatizer.lemmatize(word) in ['share'] for word in words]):\n",
    "        shareCount+=1\n",
    "        shareFile.write(title)\n",
    "        shareFile.write('\\n')\n",
    "    if any([wordnet_lemmatizer.lemmatize(word) in ['pay'] for word in words]):\n",
    "        payCount+=1\n",
    "        payFile.write(title)\n",
    "        payFile.write('\\n')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smFile.close() \n",
    "winFile.close() \n",
    "dieFile.close() \n",
    "injureFile.close() \n",
    "celebrateFile.close() \n",
    "fineFile.close() \n",
    "banFile.close() \n",
    "namedFile.close() \n",
    "tweetFile.close() \n",
    "trollFile.close() \n",
    "shareFile.close() \n",
    "questionFile.close() \n",
    "inviteFile.close() \n",
    "payFile.close() \n",
    "recordFile.close() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dy'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet_lemmatizer.lemmatize('dies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1564 570 14 47 21 43 75 59 159 0 70 0 0 33 0\n"
     ]
    }
   ],
   "source": [
    "print(smCount ,winCount ,dieCount ,injureCount,celebrateCount,fineCount ,banCount ,namedCount ,tweetCount ,trollCount ,shareCount ,questionCount,inviteCount,payCount ,recordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smCount  1564 winCount  570 dieCount  14 injureCount 47 celebrateCount 21 fineCount  43 banCount  75 namedCount  59 tweetCount  159 trollCount  0 shareCount  70 questionCount 0 inviteCount 0 payCount  33 recordCount 0\n"
     ]
    }
   ],
   "source": [
    "print('smCount ', smCount ,\n",
    "'winCount ', winCount ,\n",
    "'dieCount ', dieCount ,\n",
    "'injureCount', injureCount,\n",
    "'celebrateCount', celebrateCount,\n",
    "'fineCount ', fineCount ,\n",
    "'banCount ', banCount ,\n",
    "'namedCount ', namedCount ,\n",
    "'tweetCount ', tweetCount ,\n",
    "'trollCount ', trollCount ,\n",
    "'shareCount ', shareCount ,\n",
    "'questionCount', questionCount,\n",
    "'inviteCount', inviteCount,\n",
    "'payCount ', payCount ,\n",
    "'recordCount', recordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/madhuripalagummi/anaconda3/bin/python'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
